# ğŸ§  **ChatDOCX** â€” Talk to Your Documents Seamlessly

> *ChatDOCX â€” Talk to Your Documents Seamlessly using RAG-based AI.*

ChatDOCX is an intelligent document chat application that allows you to upload PDF and DOCX files and have natural conversations with them using advanced RAG (Retrieval-Augmented Generation) technology with **Query Translation** and **RAG Fusion** for enhanced accuracy and comprehensive document understanding.

## âœ¨ **Features**

- ğŸ“„ **Upload & Chat** with PDF and DOCX files
- ğŸ§  **Advanced RAG** with Query Translation and RAG Fusion
- ğŸ”„ **Multi-Query Processing** for enhanced document retrieval
- ğŸ¨ **Modern UI** with dark theme and smooth animations
- ğŸš€ **Intelligent backend** with parallel query processing
- ğŸ’¬ **Natural conversations** with your documents
- ğŸ”„ **Session management** for multiple document chats
- âš¡ **Enhanced accuracy** through RAG Fusion techniques

## ğŸš€ **Quick Start**

### 1. **Clone the Repository**
```bash
git clone <your-repo-url>
cd pdf_reader_rag
```

### 2. **Backend Setup**
```bash
cd back-end
pip install -r requirements.txt
python main.py
```
*Backend runs on `http://localhost:3000`*

### 3. **Frontend Setup**
```bash
cd front-end
npm install
npm run dev
```
*Frontend runs on `http://localhost:8080`*

### 4. **Start Chatting**
- Open your browser to `http://localhost:8080`
- Upload a PDF or DOCX file
- Start chatting with your document!

## ğŸ› ï¸ **Tech Stack**

### **Frontend**
- âš›ï¸ **React** with TypeScript
- ğŸ¨ **TailwindCSS** for styling
- ğŸ­ **Framer Motion** for animations
- ğŸ§© **shadcn/ui** components

### **Backend**
- ğŸ **Python Flask** API
- ğŸ§  **Advanced LangChain** RAG pipeline
- ğŸ”„ **Query Translation** for multi-query processing
- ğŸ”€ **RAG Fusion** for enhanced retrieval
- ğŸ” **Qdrant** vector database
- ğŸ¤– **Google Gemini** AI model
- ğŸ“„ **Document processing** (PDF/DOCX)
- âš¡ **OpenAI Embeddings** for improved accuracy

### **Database/Storage**
- ğŸ—„ï¸ **Qdrant** vector store for embeddings
- ğŸ“ **Temporary file processing**

## ğŸ“š **Documentation**

- ğŸ‘‰ **[Backend Guide](./back-end/README.md)** â€” API endpoints, setup, and configuration
- ğŸ‘‰ **[Frontend Guide](./front-end/README.md)** â€” UI components and development setup

## ğŸ”§ **Configuration**

### **Environment Variables**
Create a `.env` file in the `back-end` directory:

```env
QDRANT_URL=http://localhost:6333
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
```

### **Qdrant Setup**
Make sure Qdrant is running:
```bash
docker run -p 6333:6333 qdrant/qdrant
```

## ğŸ¯ **How It Works**

1. **Upload** â†’ Upload PDF/DOCX files through the web interface
2. **Process** â†’ Documents are split into chunks and embedded using OpenAI embeddings
3. **Store** â†’ Chunks are stored in Qdrant vector database
4. **Query Translation** â†’ User queries are transformed into multiple related queries
5. **RAG Fusion** â†’ Parallel retrieval using original + transformed queries
6. **Enhanced Context** â†’ Combines results from all query variations
7. **Chat** â†’ Enriched context is sent to Gemini AI for responses
8. **Respond** â†’ AI generates highly accurate, context-aware responses

## ğŸ¤ **Contributing**

We welcome contributions! Please feel free to submit issues and pull requests.

---

**Happy Document Chatting! ğŸš€**